# QuickChat Spark ETL Pipeline

A comprehensive Apache Spark ETL pipeline for QuickChat data lake architecture, implementing Bronze â†’ Silver â†’ Gold medallion architecture with Delta Lake.

## Related Services

This ETL pipeline works in conjunction with other QuickChat microservices:

| Service | Purpose | Relationship |
|---------|---------|--------------|
| **ml-service** | Real-time ML inference API | Consumes ML features from Gold layer |
| **analytics-service** | Business analytics | Consumes aggregated metrics from Gold layer |
| **insights-service** | User insights dashboard | Queries curated data from Gold layer |

The **spark-etl** pipeline generates ML feature vectors in the Gold layer, which are then used by **ml-service** for real-time predictions (smart replies, sentiment analysis, user engagement scoring).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   spark-etl    â”‚â”€â”€â”€â”€â–¶â”‚   Gold Layer    â”‚â”€â”€â”€â”€â–¶â”‚   ml-service    â”‚
â”‚  (Batch ETL)   â”‚     â”‚  (Features DB)  â”‚     â”‚  (Inference)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                               â”‚
        â”‚                                               â–¼
        â”‚                                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                       â”‚ Real-time APIs  â”‚
        â”‚                                       â”‚ - Smart Reply   â”‚
        â”‚                                       â”‚ - Sentiment     â”‚
        â”‚                                       â”‚ - Engagement    â”‚
        â”‚                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ analytics-svc  â”‚
â”‚ insights-svc   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DATA SOURCES                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MongoDB         â”‚  MySQL          â”‚  Kafka          â”‚  S3          â”‚
â”‚  (Messages,      â”‚  (Users,        â”‚  (Real-time     â”‚  (Media      â”‚
â”‚   Conversations, â”‚   Auth)         â”‚   Events)       â”‚   Files)     â”‚
â”‚   Calls)         â”‚                 â”‚                 â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚                 â”‚
         â–¼                  â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BRONZE LAYER (Raw)                              â”‚
â”‚  â€¢ Raw data ingestion                                               â”‚
â”‚  â€¢ Minimal transformations                                          â”‚
â”‚  â€¢ Ingestion metadata added                                         â”‚
â”‚  â€¢ Partitioned by date                                              â”‚
â”‚  Format: Delta Lake                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SILVER LAYER (Cleaned)                          â”‚
â”‚  â€¢ Data quality filtering                                           â”‚
â”‚  â€¢ Deduplication                                                    â”‚
â”‚  â€¢ Enrichment with derived fields                                   â”‚
â”‚  â€¢ Schema enforcement                                               â”‚
â”‚  Format: Delta Lake (Parquet)                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      GOLD LAYER (Curated)                            â”‚
â”‚  â€¢ Business aggregations                                            â”‚
â”‚  â€¢ Daily/Weekly/Monthly metrics                                     â”‚
â”‚  â€¢ User engagement scores                                           â”‚
â”‚  â€¢ ML feature vectors                                               â”‚
â”‚  Format: Delta Lake                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
spark-etl/
â”œâ”€â”€ build.sbt                           # SBT build configuration
â”œâ”€â”€ project/
â”‚   â”œâ”€â”€ build.properties               # SBT version
â”‚   â”œâ”€â”€ plugins.sbt                    # SBT plugins
â”‚   â””â”€â”€ Dependencies.scala             # Dependency versions
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ resources/
â”‚   â”‚   â”‚   â””â”€â”€ application.conf       # Application configuration
â”‚   â”‚   â””â”€â”€ scala/com/quickchat/etl/
â”‚   â”‚       â”œâ”€â”€ config/
â”‚   â”‚       â”‚   â””â”€â”€ AppConfig.scala    # Configuration case classes
â”‚   â”‚       â”œâ”€â”€ models/
â”‚   â”‚       â”‚   â””â”€â”€ Models.scala       # Data models
â”‚   â”‚       â”œâ”€â”€ transformers/
â”‚   â”‚       â”‚   â””â”€â”€ CommonTransformers.scala
â”‚   â”‚       â”œâ”€â”€ utils/
â”‚   â”‚       â”‚   â”œâ”€â”€ SparkSessionBuilder.scala
â”‚   â”‚       â”‚   â””â”€â”€ DeltaLakeUtils.scala
â”‚   â”‚       â””â”€â”€ jobs/
â”‚   â”‚           â”œâ”€â”€ bronze/
â”‚   â”‚           â”‚   â”œâ”€â”€ BronzeMessagesJob.scala
â”‚   â”‚           â”‚   â”œâ”€â”€ BronzeUsersJob.scala
â”‚   â”‚           â”‚   â”œâ”€â”€ BronzeConversationsJob.scala
â”‚   â”‚           â”‚   â””â”€â”€ BronzeCallsJob.scala
â”‚   â”‚           â”œâ”€â”€ silver/
â”‚   â”‚           â”‚   â”œâ”€â”€ SilverMessagesJob.scala
â”‚   â”‚           â”‚   â”œâ”€â”€ SilverUsersJob.scala
â”‚   â”‚           â”‚   â””â”€â”€ SilverUserActivityJob.scala
â”‚   â”‚           â”œâ”€â”€ gold/
â”‚   â”‚           â”‚   â”œâ”€â”€ DailyMetricsJob.scala
â”‚   â”‚           â”‚   â”œâ”€â”€ UserEngagementJob.scala
â”‚   â”‚           â”‚   â””â”€â”€ MLFeaturesJob.scala
â”‚   â”‚           â””â”€â”€ streaming/
â”‚   â”‚               â””â”€â”€ KafkaStreamingJob.scala
â”‚   â””â”€â”€ test/
â”‚       â””â”€â”€ scala/com/quickchat/etl/   # Test files
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile                     # Spark ETL Docker image
â”‚   â”œâ”€â”€ docker-compose.yml             # Full infrastructure
â”‚   â”œâ”€â”€ spark-defaults.conf            # Spark configuration
â”‚   â””â”€â”€ log4j2.properties              # Logging configuration
â””â”€â”€ scripts/
    â”œâ”€â”€ run-etl.sh                     # ETL runner script
    â””â”€â”€ airflow/dags/
        â””â”€â”€ quickchat_etl_dag.py       # Airflow DAG
```

## ğŸš€ Quick Start

### Prerequisites

- Java 17+
- Scala 2.12
- SBT 1.9+
- Docker & Docker Compose
- Apache Spark 3.5.0

### Build

```bash
# Build the project
cd spark-etl
sbt clean compile

# Run tests
sbt test

# Build fat JAR
sbt assembly
```

### Run Locally

```bash
# Run a single job
./scripts/run-etl.sh bronze-messages

# Run all Bronze layer jobs
./scripts/run-etl.sh bronze-all

# Run complete pipeline
./scripts/run-etl.sh full-pipeline
```

### Run with Docker

```bash
# Start infrastructure
cd docker
docker-compose up -d

# Access UIs:
# - Spark Master: http://localhost:8080
# - Spark History: http://localhost:18080
# - MinIO Console: http://localhost:9001
# - Kafka UI: http://localhost:8090
# - Airflow: http://localhost:8085
```

## ğŸ“Š ETL Jobs

### Bronze Layer (Raw Data)

| Job | Description | Source | Schedule |
|-----|-------------|--------|----------|
| BronzeMessagesJob | Extract messages | MongoDB | Hourly |
| BronzeUsersJob | Extract users | MongoDB + MySQL | Daily |
| BronzeConversationsJob | Extract conversations | MongoDB | Daily |
| BronzeCallsJob | Extract calls | MongoDB | Hourly |

### Silver Layer (Cleaned)

| Job | Description | Dependencies | Schedule |
|-----|-------------|--------------|----------|
| SilverUsersJob | Clean & enrich users | BronzeUsers | Daily |
| SilverMessagesJob | Clean & enrich messages | BronzeMessages, SilverUsers | Hourly |
| SilverUserActivityJob | Calculate daily activity | SilverMessages | Daily |

### Gold Layer (Aggregated)

| Job | Description | Dependencies | Schedule |
|-----|-------------|--------------|----------|
| DailyMetricsJob | Platform-wide daily metrics | Silver layer | Daily |
| UserEngagementJob | Per-user engagement scores | Silver layer | Daily |
| MLFeaturesJob | ML feature vectors | Silver layer | Daily |

### Streaming

| Job | Description | Source | Mode |
|-----|-------------|--------|------|
| KafkaStreamingJob | Real-time ingestion | Kafka | Continuous |

## âš™ï¸ Configuration

### Environment Variables

```bash
# Data Lake
export DATA_LAKE_PATH=s3a://quickchat-data-lake

# MongoDB
export MONGODB_URI=mongodb://localhost:27017
export MONGODB_DATABASE=quickchat

# MySQL
export MYSQL_URL=jdbc:mysql://localhost:3306/quickchat_users
export MYSQL_USER=root
export MYSQL_PASSWORD=password

# Kafka
export KAFKA_BOOTSTRAP_SERVERS=localhost:9092

# AWS S3
export AWS_ACCESS_KEY_ID=your-access-key
export AWS_SECRET_ACCESS_KEY=your-secret-key
export AWS_REGION=us-east-1
```

## ğŸ“ˆ Metrics Generated

### Daily Metrics
- DAU (Daily Active Users)
- Total messages, calls
- Message types distribution
- Peak activity hours
- New users, conversations

### User Engagement
- Engagement score (0-100)
- Activity trend (increasing/stable/decreasing)
- Churn risk (low/medium/high)
- User segment (power_user/regular/casual/at_risk/churned)

### ML Features
- Activity features (messages, calls by time window)
- Social features (contacts, groups)
- Temporal features (preferred hours, weekday ratio)
- Velocity features (message rate trends)

## ğŸ”§ Development

### Adding a New Job

1. Create job class in appropriate layer package
2. Extend common patterns from existing jobs
3. Add to Airflow DAG
4. Add to run-etl.sh script

### Testing

```bash
# Run all tests
sbt test

# Run specific test
sbt "testOnly *BronzeMessagesJobSpec"
```

## ğŸ“ License

MIT License - QuickChat Team
